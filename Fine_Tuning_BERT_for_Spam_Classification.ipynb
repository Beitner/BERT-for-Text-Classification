{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_Tuning_BERT_for_Spam_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beitner/BERT-for-Text-Classification/blob/main/Fine_Tuning_BERT_for_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# BERT fine tuning for text classification\n",
        "\n",
        "In this notebook we will fine tune BERT and create a CNN to be able to classify text (spam or not spam).\n",
        "\n",
        "We will use BERT-base pretrained model as our initial model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4cd6de-5f2d-4362-ac88-b8bed05394b1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcpr9FyhXqSn",
        "outputId": "5990eee3-48ad-49f2-997c-724efa6f71e6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/spam.csv\",encoding='latin1')"
      ],
      "metadata": {
        "id": "LObkSItTXU_L"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJrQFQgN_BE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8a3c7595-b8af-4211-9f07-09e390838181"
      },
      "source": [
        "# df = pd.read_csv(\"spam.csv\",encoding='latin1')\n",
        "df=df[[\"v1\",\"v2\"]]\n",
        "df=df.rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
        "df['label'] = df['label'].replace({'ham':0, 'spam':1})\n",
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51674e3e-d9e8-4207-bc8b-f9f9af7a3e32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51674e3e-d9e8-4207-bc8b-f9f9af7a3e32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51674e3e-d9e8-4207-bc8b-f9f9af7a3e32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51674e3e-d9e8-4207-bc8b-f9f9af7a3e32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzPPOrVQWiW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949fbd1b-1bd3-4d0e-9cc9-e49adcad6fec"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24677ddf-7b0e-4fe6-e986-d8a63fc315b6"
      },
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.865937\n",
              "1    0.134063\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dece9458-2aad-499d-9e96-80f31202ff95"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "\n",
        "\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYpg76qf5DFn",
        "outputId": "966e5b8c-a9df-49db-e831-11614280d593"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6082fbea-9ee5-4d70-d9e7-794947cadaf2"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2eb8db02-d231-4683-c418-e8c92035cea1"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff40e8cb590>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 25"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08782c4-28bb-47d0-bc8e-36721409e8a0"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xspGkyfv8omJ",
        "outputId": "6da790d1-79de-4dbd-c58e-1cbc97b36658"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=25, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H34ux0O8BkiM",
        "outputId": "f905826f-b592-4224-b98a-4bcc85530d75"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  2004,  1037,  5068, 23569,  2378,  4942, 29234,  2099, 24471,\n",
              "          4009,  1018,  1037, 29646, 18613,  5592, 29536, 22368,  2097,  2022,\n",
              "          3133,  2006, 24306,  1997,   102]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_NET(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_NET, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_NET(bert)\n",
        "\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 0.03)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba70d488-df60-45bb-d639-cd5579376b81"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.57748121 3.72658863]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 20"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc3bd31-f21b-4919-c96c-cc4b2ed579e3"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 10.207\n",
            "Validation Loss: 0.464\n",
            "\n",
            " Epoch 2 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.491\n",
            "Validation Loss: 1.084\n",
            "\n",
            " Epoch 3 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.808\n",
            "Validation Loss: 0.183\n",
            "\n",
            " Epoch 4 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.369\n",
            "Validation Loss: 0.221\n",
            "\n",
            " Epoch 5 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.339\n",
            "Validation Loss: 0.158\n",
            "\n",
            " Epoch 6 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.391\n",
            "Validation Loss: 0.164\n",
            "\n",
            " Epoch 7 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.630\n",
            "Validation Loss: 0.192\n",
            "\n",
            " Epoch 8 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.356\n",
            "Validation Loss: 0.206\n",
            "\n",
            " Epoch 9 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.310\n",
            "Validation Loss: 0.156\n",
            "\n",
            " Epoch 10 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.573\n",
            "Validation Loss: 0.140\n",
            "\n",
            " Epoch 11 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.485\n",
            "Validation Loss: 0.343\n",
            "\n",
            " Epoch 12 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 0.207\n",
            "\n",
            " Epoch 13 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.339\n",
            "Validation Loss: 0.149\n",
            "\n",
            " Epoch 14 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.311\n",
            "Validation Loss: 0.171\n",
            "\n",
            " Epoch 15 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.265\n",
            "Validation Loss: 0.128\n",
            "\n",
            " Epoch 16 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.403\n",
            "Validation Loss: 0.143\n",
            "\n",
            " Epoch 17 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 3.602\n",
            "Validation Loss: 0.142\n",
            "\n",
            " Epoch 18 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.275\n",
            "Validation Loss: 0.158\n",
            "\n",
            " Epoch 19 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.277\n",
            "Validation Loss: 0.168\n",
            "\n",
            " Epoch 20 / 20\n",
            "  Batch    50  of    140.\n",
            "  Batch   100  of    140.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.356\n",
            "Validation Loss: 0.173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef895d8a-1e1a-4136-8790-19c9c4a76b71"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94       483\n",
            "           1       0.59      0.97      0.73        75\n",
            "\n",
            "    accuracy                           0.91       558\n",
            "   macro avg       0.79      0.93      0.84       558\n",
            "weighted avg       0.94      0.91      0.91       558\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "54e62514-16a3-404a-aa0c-60034a0c5ce5"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0   1\n",
              "row_0         \n",
              "0      432  51\n",
              "1        2  73"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48fd3169-bfa3-4459-bb4b-fd2bcf782d6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>432</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48fd3169-bfa3-4459-bb4b-fd2bcf782d6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48fd3169-bfa3-4459-bb4b-fd2bcf782d6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48fd3169-bfa3-4459-bb4b-fd2bcf782d6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}